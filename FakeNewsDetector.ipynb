{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b58fda5b",
   "metadata": {
    "dc": {
     "key": "4"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 1. Fake News Detector \n",
    "<p>Fake news is false or misleading information presented as news. Fake news often has the aim of damaging the reputation of a person or entity, or making money through advertising revenue. The term was first used in the 1890s when sensational reports in newspapers were common.</p>\n",
    "<p><img src=\"https://www.pngall.com/wp-content/uploads/4/Fake-News-Stamp-PNG.png\" alt=\"Fake News Logo\"></p>\n",
    "<p>I am going to build a model that will accurately classify news articles as REAL or FAKE.  Using sklearn, I will build a <a  href=\"https://stackoverflow.com/questions/25902119/scikit-learn-tfidfvectorizer-meaning\">TfidfVectorizer</a> on the dataset. Then, I will initialize a <a href=\"https://www.geeksforgeeks.org/passive-aggressive-classifiers/\">PassiveAggressive Classifier</a> and fit the model. In the end, the accuracy score and the confusion matrix show how well the model fares. Let's look at the initial dataset I will use for this project:</p>\n",
    "<ul>\n",
    "<li><code>news.csv</code>: This dataset has a shape of 7796Ã—4. The first column identifies the news, the second and third are the title and text, and the fourth column has labels denoting whether the news is REAL or FAKE.</li></ul>\n",
    "<p>First of all,  libraries that are needed to complete and run this project must be installed using: <code>pip install numpy pandas sklearn</code>. \n",
    "\n",
    "Below the necessary imports required:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f52125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b95b59f",
   "metadata": {
    "dc": {
     "key": "11"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 2. Data Import and Splitting\n",
    "<p>Now, at this point I must load the data into a dataframe, and split the dataset into training and testing sets: </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "b3d8659a",
   "metadata": {
    "dc": {
     "key": "11"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "#Read the data\n",
    "df = pd.read_csv('news.csv') #ensure the full path to the data is inserted here if it is stored locally. \n",
    "#Get shape and head\n",
    "df.shape\n",
    "df.head()\n",
    "#get the labels\n",
    "labels = df.label\n",
    "labels.head()\n",
    "\n",
    "#split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['text'], labels, test_size=0.2, random_state=7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee9e7c",
   "metadata": {
    "dc": {
     "key": "18"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 3. Initialising TfidfVectorization\n",
    "<p>The next step is to initialise a TfidfVectorizer with stop words from the English language and a maximum document frequency of 0.7 (terms with a higher document frequency will be discarded). Stop words are the most common words in a language that are to be filtered out before processing the natural language data. Initialising a TfidfVectorizer turns a collection of raw documents into a matrix of TF-IDF features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1c36a0e6",
   "metadata": {
    "dc": {
     "key": "18"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer=TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "# this code fits and transforms train set and transforms the test set\n",
    "tfidf_train=tfidf_vectorizer.fit_transform(x_train) \n",
    "tfidf_test=tfidf_vectorizer.transform(x_test)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6f374",
   "metadata": {
    "dc": {
     "key": "25"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 4. Initialise PassiveAggressiveClassifer\n",
    "\n",
    "<p>This section initialises the PassiveAggressiveClassifier. It will be fit on tfidf_train and y_train. Then, I will predict on the test set from the TfidfVectorizer and calculate the accuracy with <code>accuracy_score()</code> from sklearn.metrics.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "41c78b58",
   "metadata": {
    "dc": {
     "key": "25"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.66%\n"
     ]
    }
   ],
   "source": [
    "#Initialize a PassiveAggressiveClassifier\n",
    "pac=PassiveAggressiveClassifier(max_iter=50)\n",
    "pac.fit(tfidf_train,y_train)\n",
    "\n",
    "#Predict on the test set and calculate accuracy\n",
    "y_pred=pac.predict(tfidf_test)\n",
    "score=accuracy_score(y_test,y_pred)\n",
    "print(f'Accuracy: {round(score*100,2)}%') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be05f58",
   "metadata": {
    "dc": {
     "key": "32"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 5. Accuracy\n",
    "<p>According to the above we reached an accuracy of 92.66% with this model. We then must print out a confusion matrix to gain insight into the number of false and true negatives and positives.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "22fa2d36",
   "metadata": {
    "dc": {
     "key": "32"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[588,  50],\n",
       "       [ 43, 586]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build confusion matrix\n",
    "confusion_matrix(y_test,y_pred, labels=['FAKE','REAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcc1b25",
   "metadata": {
    "dc": {
     "key": "39"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "tags": [
     "context"
    ]
   },
   "source": [
    "## 6. Summary\n",
    "<p>Based on this output, we have 588 true positives, 586 true negatives, 50 false positives, and 43 false negatives. I took a political dataset, implemented a TfidfVectorizer, initialized a PassiveAggressiveClassifier, and fit a model. I ended up obtaining an accuracy of 92.66% in magnitude.\n",
    "\n",
    "Now, this model can be used to test further articles if arranged in the same format - minimal code alterations are required if the dataset needs to be expanded in anyway. </p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
